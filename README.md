<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script>
## Merging过程
Mapping的过程我们用传统数据库建立了三个新表, 用来记录图模型的顶点, 和各类边的属性。这三张表将作为merging算法的直接输入。由于传统关系型数据库无法快速处理这样的图模型, 以及进行复杂的图形算法。我们选择使用Spark自带的图模型组件GraphX来实现merge算法。
###	GraphX简介
GraphX是Spark中用于图(如Web-Graphs and Social Networks)和图并行计算(如PageRank and Collaborative Filtering)的API, 可以认为是GraphLab(C++)和Pregel(C++)在Spark(Scala)上的重写及优化, 跟其他分布式图计算框架相比, GraphX最大的贡献是, 在Spark之上提供一站式数据解决方案，可以方便且高效地完成图计算的一整套流水作业。

目前行业上也有其他的图模型数据库, 最常见的如Neo4J。 相比于这些其他的图数据库, GraphX不仅提供了图存储的可能, 而且提供了图计算的工具。Graphx是Spark生态中的非常重要的组件，融合了图并行以及数据并行的计算优势, 和Spark系统有很好的兼容性。

### Merge逻辑
 
图3.1	Merge流程

#### Step 1 在GraphX中构建图模型
利用Mapping算法输出的三张表在GraphX中建立图模型。

根据Mapping输出的结果, 这个图模型的节点至少包含以下信息:
- Vertex ID: 	即表AllIDValues的主键；
-	对应的ID类型: 表AllIDValues中的IDName列, 区分不同的；
-	对应的ID值:	表AllIDValues中的IDValue列；	
-	初始权重w_1: 由权重体系定义, 至少将由来源表、来源表列名、以及ID类型共同决定；
-	时间间隔: 该ID最后一次业务登记的时间和现在的间隔天数；如果没有相关记录, 记为正无穷。

图模型上的边分为两类(图2.1中的红边和黑边):
-	来自同一条记录中的ID信息节点相连(黑边)；
-	ID值相等的节点相连(红边)。
	
#### Step 2 更新各个ID节点的权重
权重的计算是整个merge算法中最为重要的一块,因为这些ID的权重将作为判断其可信度的唯一标准, 
我们将利用最终计算出的权重值来对同一类的ID进行排序。
我们的计算权重将会考虑多方面的因素: ID的来源表、ID的类型、ID的更新时间以及ID之间的关联关系。
这些关系将在图模型中做一个汇总计算, 具体计算流程参见图3.3, 得到一个最终的权重。
 
图 3.2 权重计算过程

- 其中数据源权重表和IDName权重表由相关数据源优先级和各ID的优先级确定, 存储在数据库中。这两个数据表确定了每个ID节点的基础权重\\( w_1 \\)；
- 更新时间通过读取源数据的信息获得, 通过step A的转换获得新的时间权重\\(T\\)。例如每个ID可能有多个来源, 其时间是不同的, 我们将这些ID的时间更新为最近的时间；
- 通过建立的图模型计算跳表数\\(N \\): 跳表数表示了个ID之间的关联关系, 可以用于计算关联权重；
- 利用得到的\\(w_1\\), N, T这3个不同来源的信息的每个节点的计算权重\\(w_final\\)；

以上步骤都是对每个独立的ID节点进行计算操作, 在step 2.D中会将不同的节点根据ID值和ID类型进行归类, 
将具有相同ID值的节点权重相加, 得到一个最终的ID权重信息表。

这就是整个权重计算体系的大致流程, 下面将具体介绍A、B、C、D四个步骤的详细算法及计算方法:

##### A.时间信息
时间信息可以帮助我们定义一个时间衰减系数, 一般来说如果一条记录来自于1年之前, 其可信程度自然不会太高；
但如果一条记录来自几天前, 其可信程度就会相对提升。

如图2.1, 对于相同一个手机号MA, 该手机号信息来自几条不同的信息(MA1和MA2),他们的更新时间可能各不相同, 
需要将这些时间全部替换为最近的更新时间(或者可以补充原来缺失的时间信息)。比如, MA1信息来自10天前, MA2信息来自100天前, 
那么我们需要将MA2的时间更新至10天前；又或者MA1信息并没有记录时间信息(正无穷), MA2信息来自100天前, 我们将MA1的时间信息也补充为100天前。

对于这一类型的时间更新, 我们在图算法中用信息传递的算法实现。因为ID值相同的节点都通过第二类边(红边)相连。
我们在原先的图结构中找到所有点-边-点(GraphX中已定义了triplet类)结构, 边中包含了边的类型信息, 点中包含了时间信息(date)。

```
FOR EACH 点1-边-点2 in GRAPH
    IF 边.类型 = 2 THEN
	    点1.date = min(点1.date, 点2.date)
	    点2.date = min(点1.date, 点2.date)
    END IF
END FOR
```

重复运行上述算法, 直至图中顶点的时间信息不再变化。

##### B.利用最短路径算法得到关联权重N
图论中的最短路径算法可以用来判断节点1和节点2是否通过某些边相连
(可以直接相连, 也可以间接相连), 同时可以计算这两个节点之间的最短路径。
一般情况下, 我们将某个节点设为初始节点(作为节点1), 判断其与其他所有节点是否相连, 并计算初始节点与其关联点之间的最短路径(若不相连, 则没有最短距离, 默认为正无穷)。
 
图2.1
以图2.1的图结构为例具体说明:
以CA1为初始节点, 经典的最短路径算法(将所有边权重设为1)将给出结果:

初始节点	目标节点	ID类型	ID值	最短路径	跳表数	w_final
CA1	MA1	MOBILE	MA	1	0	0.5
CA1	EA1	EMAIL	EA	2	0	0.6
CA1	CA3	CUST_ID	CA	1	1	0.2
CA1	MeA3	MEMBER_ID	MeA	2	1	0.5
CA1	MA2	MOBILE	MA	1	1	0.4
CA1	EC2	EMAIL	EC	3	1	0.1
CA1	CB1	CUST_ID	CB	∞	∞	
CA1	MB1	MEMBER_ID	MB	∞	∞	
CA1	EB1	EMAIL	EB	∞	∞	
表3.1	

适当修改传统的最短路径算法, 给两类不同的边给予不同的权重。
-	黑边表示两个ID来自同一条记录, 认为是一种强关联, 权重设为0；
-	红边表示通过该ID将两条记录联系起来, 看做一种弱关联,将其权重设为1；

利用最短路径算法求出新的最短路径, 此时这个新的值(表3.1中最后一列)表示
的是我们跳了多少张表找到了和这个CA1节点相关联的记录, 称之为跳表数。
跳表数越大, 表示获得该信息跳过的表格越多, 信息的可信度越低。

下图展示了在原有的14张客户信息相关表中, 给定
CUST_ID = 0AF2AB6D-2644-4526-A820-F08AB4E52E53, 
找到所有与它相连的ID及属性(一共找到40个节点), 
最右一个数字表示我们计算的跳表数:
 
图3.3	与某ID相连的ID节点(部分)
	
##### C.计算各节点的计算权重
第三步之后, 每个目标ID节点相对于初始节点存在3个用于展现两者关系的数值
-	初始权重w_1:	由来源表、来源表列名、以及ID类型共同决定；
-	时间间隔T:	表示该ID的新鲜程度
-	跳表数N:	  	表示两个节点之间相连关系的强弱

我们建立一个数学模型
$$ w_{final} = F(w_1, T, N) = w_1 * f_t(T) * \alpha^N $$
用来将这三个数值统一起来, 用一个\\( w_{final}\\)来表示这个ID几点最终的可靠程度(或者权重)。这个函数F至少需要满足以下特性:
-	F取值大于等于0；
-	函数F关于w_1递增, 关于T递减, 关于N递减。
于是我们可以在表3.1中加入我们对该ID权重的最后判断\\(w_{final}\\)

##### D.将相同值的ID归类 
在表3.1中, 我们根据ID类型和ID值将这些和初始节点相连的ID归类, 将相同的ID值的权重相加。从业务角度来看某个ID出现次数越多, 相对来说他的可信度就会提升, 每次出现我们都会或多或少地提升其可信度。于是得到:

初始节点	ID类型	ID值	w_final
CA1	MOBILE	MA	0.9
CA1	EMAIL	EA	0.6
CA1	CUST_ID	CA	0.2
CA1	MEMBER_ID	MeA	0.5
CA1	EMAIL	EC	0.1

表3.2
回到初始从业务的数据, 我们找到CUST_ID=0AF2AB6D-2644-4526-A820-F08AB4E52E53的相关信息有:
 
图3.4	归并后的各个ID
在这个结果中,我们一共找到了和该顾客相关的2个手机号18996062269和13905221314:其中第一个权重为2.377, 第二个权重为1.391。因此第一个手机的可能性较大。
这里我们会碰到2.3.2章节中情景2相同的问题, 即我们可能遇到ID类型不一致但ID值相同的节点, 这个时候我们不能简单地通过传统的归类方式去处理这类问题。但是我们可以发现ID值相等的节点在我们的图模型中用第二类边(红边)相连, 于是可以通过找到所有仅仅通过红边相连的节点(建立一个子图, 利用最短路径算法), 将它们的最终权重相加。然后根据不同ID类型和ID值将结果列出。
#### Step 3	筛选ID值并入库
在最终的结果中, 我们根据最终的权重和对相同类型的ID进行筛选, 权重越大表示该ID越可靠。
对所有的CUST_ID节点执行上述操作(step 2 + step 3),最终得到一张带所有用户相关ID信息的宽表 T_merge
